{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e40f997-eca2-494e-aef4-25d896de9406",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Basic Statistics\n",
    "\n",
    "Some of the contents are from stat.yale.edu<br>\n",
    "Revised by Junyao Yang\n",
    "\n",
    "### Statistics theory is widely applied in data science, including but not limit to:\n",
    "    1. Descriptive Statistics\n",
    "    2. Probability Theory and Distribution(Normal Dist, Student T Dist, and Binomial Dist)\n",
    "    3. Inferential Statistics\n",
    "    4. Correlation and Regression\n",
    "    5. Statistical Testing\n",
    "    6. Bayesian Statistics\n",
    "    \n",
    "### Here are some fundamental statistical concepts that are particularly relevant to business students:<br>\n",
    "    1. Descriptive Statistics\n",
    "        a. Mean, median and mode\n",
    "        b. Range and interquartile range\n",
    "        c. Standard deviation\n",
    "    2. Probability\n",
    "        a. Basic probability\n",
    "        b. Bayesian theory\n",
    "    3. Sampling and Sampling distributions\n",
    "        a. Sampling techniques\n",
    "        b. Sampling distribution\n",
    "    4. Inferential statistics\n",
    "        a. Confidence intervals\n",
    "        b. Statistics test\n",
    "        c. Regression Analysis\n",
    "    5. Financial Statistics\n",
    "        a. Return analysis\n",
    "        b. Risk analysis\n",
    "    6. Business Forecasting\n",
    "        a. Time and non-time series\n",
    "        b. Trend analysis\n",
    "\n",
    "<span style='color:blue'>Descriptive Statistics, Sampling and Sampling distributions, Statistical inference</span> will be briefly covered in this week. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86badea2-2f8e-412f-bc53-2b65e0996778",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57045ccc-c3d4-4c7b-94a0-ffb4ee2c6f2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>...</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7129300520</td>\n",
       "      <td>20141013T000000</td>\n",
       "      <td>221900.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1180</td>\n",
       "      <td>5650</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1180</td>\n",
       "      <td>0</td>\n",
       "      <td>1955</td>\n",
       "      <td>0</td>\n",
       "      <td>98178</td>\n",
       "      <td>47.5112</td>\n",
       "      <td>-122.257</td>\n",
       "      <td>1340</td>\n",
       "      <td>5650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6414100192</td>\n",
       "      <td>20141209T000000</td>\n",
       "      <td>538000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2570</td>\n",
       "      <td>7242</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>2170</td>\n",
       "      <td>400</td>\n",
       "      <td>1951</td>\n",
       "      <td>1991</td>\n",
       "      <td>98125</td>\n",
       "      <td>47.7210</td>\n",
       "      <td>-122.319</td>\n",
       "      <td>1690</td>\n",
       "      <td>7639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5631500400</td>\n",
       "      <td>20150225T000000</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>770</td>\n",
       "      <td>10000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>770</td>\n",
       "      <td>0</td>\n",
       "      <td>1933</td>\n",
       "      <td>0</td>\n",
       "      <td>98028</td>\n",
       "      <td>47.7379</td>\n",
       "      <td>-122.233</td>\n",
       "      <td>2720</td>\n",
       "      <td>8062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2487200875</td>\n",
       "      <td>20141209T000000</td>\n",
       "      <td>604000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1960</td>\n",
       "      <td>5000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1050</td>\n",
       "      <td>910</td>\n",
       "      <td>1965</td>\n",
       "      <td>0</td>\n",
       "      <td>98136</td>\n",
       "      <td>47.5208</td>\n",
       "      <td>-122.393</td>\n",
       "      <td>1360</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1954400510</td>\n",
       "      <td>20150218T000000</td>\n",
       "      <td>510000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1680</td>\n",
       "      <td>8080</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>1680</td>\n",
       "      <td>0</td>\n",
       "      <td>1987</td>\n",
       "      <td>0</td>\n",
       "      <td>98074</td>\n",
       "      <td>47.6168</td>\n",
       "      <td>-122.045</td>\n",
       "      <td>1800</td>\n",
       "      <td>7503</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id             date     price  bedrooms  bathrooms  sqft_living  \\\n",
       "0  7129300520  20141013T000000  221900.0         3       1.00         1180   \n",
       "1  6414100192  20141209T000000  538000.0         3       2.25         2570   \n",
       "2  5631500400  20150225T000000  180000.0         2       1.00          770   \n",
       "3  2487200875  20141209T000000  604000.0         4       3.00         1960   \n",
       "4  1954400510  20150218T000000  510000.0         3       2.00         1680   \n",
       "\n",
       "   sqft_lot  floors  waterfront  view  ...  grade  sqft_above  sqft_basement  \\\n",
       "0      5650     1.0           0     0  ...      7        1180              0   \n",
       "1      7242     2.0           0     0  ...      7        2170            400   \n",
       "2     10000     1.0           0     0  ...      6         770              0   \n",
       "3      5000     1.0           0     0  ...      7        1050            910   \n",
       "4      8080     1.0           0     0  ...      8        1680              0   \n",
       "\n",
       "   yr_built  yr_renovated  zipcode      lat     long  sqft_living15  \\\n",
       "0      1955             0    98178  47.5112 -122.257           1340   \n",
       "1      1951          1991    98125  47.7210 -122.319           1690   \n",
       "2      1933             0    98028  47.7379 -122.233           2720   \n",
       "3      1965             0    98136  47.5208 -122.393           1360   \n",
       "4      1987             0    98074  47.6168 -122.045           1800   \n",
       "\n",
       "   sqft_lot15  \n",
       "0        5650  \n",
       "1        7639  \n",
       "2        8062  \n",
       "3        5000  \n",
       "4        7503  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fname = \"../../data/kc_house_data.csv\"\n",
    "df = pd.read_csv(fname)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1304923b-f434-4e92-b074-15ef39eebf56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>condition</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.161300e+04</td>\n",
       "      <td>2.161300e+04</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>2.161300e+04</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.580302e+09</td>\n",
       "      <td>5.401822e+05</td>\n",
       "      <td>3.370842</td>\n",
       "      <td>2.114757</td>\n",
       "      <td>2079.899736</td>\n",
       "      <td>1.510697e+04</td>\n",
       "      <td>1.494309</td>\n",
       "      <td>0.007542</td>\n",
       "      <td>0.234303</td>\n",
       "      <td>3.409430</td>\n",
       "      <td>7.656873</td>\n",
       "      <td>1788.390691</td>\n",
       "      <td>291.509045</td>\n",
       "      <td>1971.005136</td>\n",
       "      <td>84.402258</td>\n",
       "      <td>98077.939805</td>\n",
       "      <td>47.560053</td>\n",
       "      <td>-122.213896</td>\n",
       "      <td>1986.552492</td>\n",
       "      <td>12768.455652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.876566e+09</td>\n",
       "      <td>3.673622e+05</td>\n",
       "      <td>0.930062</td>\n",
       "      <td>0.770163</td>\n",
       "      <td>918.440897</td>\n",
       "      <td>4.142051e+04</td>\n",
       "      <td>0.539989</td>\n",
       "      <td>0.086517</td>\n",
       "      <td>0.766318</td>\n",
       "      <td>0.650743</td>\n",
       "      <td>1.175459</td>\n",
       "      <td>828.090978</td>\n",
       "      <td>442.575043</td>\n",
       "      <td>29.373411</td>\n",
       "      <td>401.679240</td>\n",
       "      <td>53.505026</td>\n",
       "      <td>0.138564</td>\n",
       "      <td>0.140828</td>\n",
       "      <td>685.391304</td>\n",
       "      <td>27304.179631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000102e+06</td>\n",
       "      <td>7.500000e+04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>290.000000</td>\n",
       "      <td>5.200000e+02</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>290.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1900.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>98001.000000</td>\n",
       "      <td>47.155900</td>\n",
       "      <td>-122.519000</td>\n",
       "      <td>399.000000</td>\n",
       "      <td>651.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.123049e+09</td>\n",
       "      <td>3.219500e+05</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>1427.000000</td>\n",
       "      <td>5.040000e+03</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1190.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1951.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>98033.000000</td>\n",
       "      <td>47.471000</td>\n",
       "      <td>-122.328000</td>\n",
       "      <td>1490.000000</td>\n",
       "      <td>5100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.904930e+09</td>\n",
       "      <td>4.500000e+05</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.250000</td>\n",
       "      <td>1910.000000</td>\n",
       "      <td>7.618000e+03</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1560.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1975.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>98065.000000</td>\n",
       "      <td>47.571800</td>\n",
       "      <td>-122.230000</td>\n",
       "      <td>1840.000000</td>\n",
       "      <td>7620.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.308900e+09</td>\n",
       "      <td>6.450000e+05</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>2550.000000</td>\n",
       "      <td>1.068800e+04</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>2210.000000</td>\n",
       "      <td>560.000000</td>\n",
       "      <td>1997.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>98118.000000</td>\n",
       "      <td>47.678000</td>\n",
       "      <td>-122.125000</td>\n",
       "      <td>2360.000000</td>\n",
       "      <td>10083.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.900000e+09</td>\n",
       "      <td>7.700000e+06</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>13540.000000</td>\n",
       "      <td>1.651359e+06</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>9410.000000</td>\n",
       "      <td>4820.000000</td>\n",
       "      <td>2015.000000</td>\n",
       "      <td>2015.000000</td>\n",
       "      <td>98199.000000</td>\n",
       "      <td>47.777600</td>\n",
       "      <td>-121.315000</td>\n",
       "      <td>6210.000000</td>\n",
       "      <td>871200.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id         price      bedrooms     bathrooms   sqft_living  \\\n",
       "count  2.161300e+04  2.161300e+04  21613.000000  21613.000000  21613.000000   \n",
       "mean   4.580302e+09  5.401822e+05      3.370842      2.114757   2079.899736   \n",
       "std    2.876566e+09  3.673622e+05      0.930062      0.770163    918.440897   \n",
       "min    1.000102e+06  7.500000e+04      0.000000      0.000000    290.000000   \n",
       "25%    2.123049e+09  3.219500e+05      3.000000      1.750000   1427.000000   \n",
       "50%    3.904930e+09  4.500000e+05      3.000000      2.250000   1910.000000   \n",
       "75%    7.308900e+09  6.450000e+05      4.000000      2.500000   2550.000000   \n",
       "max    9.900000e+09  7.700000e+06     33.000000      8.000000  13540.000000   \n",
       "\n",
       "           sqft_lot        floors    waterfront          view     condition  \\\n",
       "count  2.161300e+04  21613.000000  21613.000000  21613.000000  21613.000000   \n",
       "mean   1.510697e+04      1.494309      0.007542      0.234303      3.409430   \n",
       "std    4.142051e+04      0.539989      0.086517      0.766318      0.650743   \n",
       "min    5.200000e+02      1.000000      0.000000      0.000000      1.000000   \n",
       "25%    5.040000e+03      1.000000      0.000000      0.000000      3.000000   \n",
       "50%    7.618000e+03      1.500000      0.000000      0.000000      3.000000   \n",
       "75%    1.068800e+04      2.000000      0.000000      0.000000      4.000000   \n",
       "max    1.651359e+06      3.500000      1.000000      4.000000      5.000000   \n",
       "\n",
       "              grade    sqft_above  sqft_basement      yr_built  yr_renovated  \\\n",
       "count  21613.000000  21613.000000   21613.000000  21613.000000  21613.000000   \n",
       "mean       7.656873   1788.390691     291.509045   1971.005136     84.402258   \n",
       "std        1.175459    828.090978     442.575043     29.373411    401.679240   \n",
       "min        1.000000    290.000000       0.000000   1900.000000      0.000000   \n",
       "25%        7.000000   1190.000000       0.000000   1951.000000      0.000000   \n",
       "50%        7.000000   1560.000000       0.000000   1975.000000      0.000000   \n",
       "75%        8.000000   2210.000000     560.000000   1997.000000      0.000000   \n",
       "max       13.000000   9410.000000    4820.000000   2015.000000   2015.000000   \n",
       "\n",
       "            zipcode           lat          long  sqft_living15     sqft_lot15  \n",
       "count  21613.000000  21613.000000  21613.000000   21613.000000   21613.000000  \n",
       "mean   98077.939805     47.560053   -122.213896    1986.552492   12768.455652  \n",
       "std       53.505026      0.138564      0.140828     685.391304   27304.179631  \n",
       "min    98001.000000     47.155900   -122.519000     399.000000     651.000000  \n",
       "25%    98033.000000     47.471000   -122.328000    1490.000000    5100.000000  \n",
       "50%    98065.000000     47.571800   -122.230000    1840.000000    7620.000000  \n",
       "75%    98118.000000     47.678000   -122.125000    2360.000000   10083.000000  \n",
       "max    98199.000000     47.777600   -121.315000    6210.000000  871200.000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Descriptive Statistics is very simple. \n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75beb92f-a324-4eb8-aeb4-d204cb0d267a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(id               3.904930e+09\n",
       " price            4.500000e+05\n",
       " bedrooms         3.000000e+00\n",
       " bathrooms        2.250000e+00\n",
       " sqft_living      1.910000e+03\n",
       " sqft_lot         7.618000e+03\n",
       " floors           1.500000e+00\n",
       " waterfront       0.000000e+00\n",
       " view             0.000000e+00\n",
       " condition        3.000000e+00\n",
       " grade            7.000000e+00\n",
       " sqft_above       1.560000e+03\n",
       " sqft_basement    0.000000e+00\n",
       " yr_built         1.975000e+03\n",
       " yr_renovated     0.000000e+00\n",
       " zipcode          9.806500e+04\n",
       " lat              4.757180e+01\n",
       " long            -1.222300e+02\n",
       " sqft_living15    1.840000e+03\n",
       " sqft_lot15       7.620000e+03\n",
       " dtype: float64,\n",
       "             id     price  bedrooms  bathrooms  sqft_living  sqft_lot  floors  \\\n",
       " 0  795000620.0  350000.0       3.0        2.5       1300.0    5000.0     1.0   \n",
       " 1          NaN  450000.0       NaN        NaN          NaN       NaN     NaN   \n",
       " 2          NaN       NaN       NaN        NaN          NaN       NaN     NaN   \n",
       " 3          NaN       NaN       NaN        NaN          NaN       NaN     NaN   \n",
       " \n",
       "    waterfront  view  condition  grade  sqft_above  sqft_basement  yr_built  \\\n",
       " 0         0.0   0.0        3.0    7.0      1300.0            0.0    2014.0   \n",
       " 1         NaN   NaN        NaN    NaN         NaN            NaN       NaN   \n",
       " 2         NaN   NaN        NaN    NaN         NaN            NaN       NaN   \n",
       " 3         NaN   NaN        NaN    NaN         NaN            NaN       NaN   \n",
       " \n",
       "    yr_renovated  zipcode      lat    long  sqft_living15  sqft_lot15  \n",
       " 0           0.0  98103.0  47.5322 -122.29         1540.0      5000.0  \n",
       " 1           NaN      NaN  47.5491     NaN            NaN         NaN  \n",
       " 2           NaN      NaN  47.6624     NaN            NaN         NaN  \n",
       " 3           NaN      NaN  47.6846     NaN            NaN         NaN  )"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Mean: The average of the given numbers and is calculated by dividing the sum of given numbers by the total number of numbers.\n",
    "### Median: The middle number; found by ordering all data points and picking out the one in the middle.\n",
    "### Mode: The most frequent numberâ€”that is, the number that occurs the highest number of times.\n",
    "df_sub = df.drop('date', axis = 1)\n",
    "df_sub.median(axis = 0), df_sub.mode(axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d8622b-fe66-4f9e-a259-43ebdecd370f",
   "metadata": {},
   "source": [
    "# Sampling \n",
    "### 1. allowing researchers to study a subset of a population \n",
    "### 2. make inferences about the entire population\n",
    "\n",
    "Different sampling techniques are employed based on the research objectives, population characteristics, and available resources.<br> \n",
    "Here are some common sampling techniques:\n",
    "\n",
    "&emsp;1.<span style='color:blue'>Simple Random Sampling:</span> Every individual in the population has an equal chance of being selected<br>\n",
    "&emsp;2.<span style='color:blue'>Stratified Random Sampling:</span> The population is divided into subgroups (strata) based on certain characteristics<br>\n",
    "&emsp;3.<span style='color:blue'>Systematic Sampling:</span> A fixed interval is selected, and every nth individual is included in the sample<br>\n",
    "&emsp;4.<span style='color:blue'>Cluster Sampling:</span> The population is divided into clusters, and a random sample of clusters is selected.<br>\n",
    "        &emsp;&emsp;This method is useful when it is more practical to sample groups rather than individuals.<br>\n",
    "&emsp;5.<span style='color:blue'>Convenience Sampling:</span> Participants are chosen based on their availability and willingness to participate.<br>\n",
    "        &emsp;&emsp;This method is quick and convenient but may lead to a biased sample.<br>\n",
    "&emsp;6.<span style='color:blue'>Purposive Sampling: </span> Researchers intentionally choose individuals who meet specific criteria.<br>\n",
    "        &emsp;&emsp;This method is subjective and relies on the researcher's judgment.<br>\n",
    "&emsp;7.<span style='color:blue'>Probability Proportional to Size Sampling:</span> Frequent occurrence data have a higher probability of being included in the sample.<br>\n",
    "        &emsp;&emsp;Useful when dealing with heterogeneous populations. <br>\n",
    "        &emsp;&emsp;A group that consists of diverse and dissimilar individuals with variations in characteristics, attributes, or traits.<br>\n",
    "&emsp;8.<span style='color:blue'>Multistage Sampling:</span> Involves multiple stages of sampling, often combining different methods.<br>\n",
    "\n",
    "The choice of a sampling technique depends on the nature of the research, the characteristics of the population, and the resources available.<br>\n",
    "It's important to select a method that minimizes bias and allows for generalization of findings to the broader population."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c3b7904-13b7-466d-894f-e213a0114ea4",
   "metadata": {},
   "source": [
    "# Inferential statistics\n",
    "\n",
    "Inferential statistics is a branch of statistics that involves making inferences, predictions, or generalizations about a population based on a sample of data from that population."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77f604a-dcac-4f9f-9419-14d047624bb4",
   "metadata": {},
   "source": [
    "### 1. Confidence Interval\n",
    "In statistical inference, one wishes to estimate population parameters using observed sample data.<br>\n",
    "A confidence interval gives an estimated range of values which is likely to include an unknown population parameter, the estimated range being calculated from a given set of sample data. (Definition taken from Valerie J. Easton and John H. McColl's Statistics Glossary v1.1)<br>\n",
    "\n",
    "The common notation for the parameter in question is $\\theta$. Often, this parameter is the population mean $\\mu$, which is estimated through the sample mean $\\bar{x}$.\n",
    "\n",
    "The level C of a confidence interval gives the probability that the interval produced by the method employed includes the true value of the parameter $\\theta$.\n",
    "\n",
    "1. <span style='color:blue'>Point Estimate (xÌ„ or pÌ‚):</span>\n",
    "The sample statistic that serves as the best estimate of the population parameter.\n",
    "\n",
    "2. <span style='color:blue'>Margin of Error (E): </span>\n",
    "The range within which the true population parameter is expected to fall.<br>\n",
    "Calculated based on the standard error of the point estimate and the chosen level of confidence.<br>\n",
    "\n",
    "Confidence Interval = Point Estimate Â± Margin of Error\n",
    "\n",
    "Based on the Central Limit Theory(CLT), it's good to have a sample size greater or equal to 30 for a basic normal distribution assumption. \n",
    "\n",
    "##### Example\n",
    "Suppose a student measuring the boiling temperature of a certain liquid observes the readings (in degrees Celsius) 102.5, 101.7, 103.1, 100.9, 100.5, and 102.2 on 6 different samples of the liquid. He calculates the sample mean to be 101.82. If he knows that the standard deviation for this procedure is 1.2 degrees, what is the confidence interval for the population mean at a 95% confidence level?\n",
    "\n",
    "In other words, the student wishes to estimate the true mean boiling temperature of the liquid using the results of his measurements. If the measurements follow a normal distribution, then the sample mean will have the distribution $N(\\mu, \\frac{\\sigma}{\\sqrt{n}})$. Since the sample size is 6, the standard deviation of the sample mean is equal to 1.2/sqrt(6) = 0.49.\n",
    "\n",
    "The selection of a confidence level for an interval determines the probability that the confidence interval produced will contain the true parameter value. Common choices for the confidence level C are 0.90, 0.95, and 0.99. These levels correspond to percentages of the area of the normal density curve. For example, a 95% confidence interval covers 95% of the normal curve -- the probability of observing a value outside of this area is less than 0.05. Because the normal curve is symmetric, half of the area is in the left tail of the curve, and the other half of the area is in the right tail of the curve. As shown in the diagram to the right, for a confidence interval with level C, the area in each tail of the curve is equal to (1-C)/2. For a 95% confidence interval, the area in each tail is equal to 0.05/2 = 0.025.\n",
    "\n",
    "The value $z^{*}$ representing the point on the standard normal density curve such that the probability of observing a value greater than $z^{*}$ is equal to $p$ is known as the upper $p$ critical value of the standard normal distribution. For example, if $p$ = 0.025, the value $z^{*}$ such that $P(Z > z^{*}) = 0.025$, or $(Z < z^{*}) = 0.975$, is equal to 1.96. For a confidence interval with level C, the value p is equal to (1-C)/2. A 95% confidence interval for the standard normal distribution, then, is the interval (-1.96, 1.96), since 95% of the area under the curve falls within this interval.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28ce289-51a1-4d60-ad48-e575dd2bec50",
   "metadata": {},
   "source": [
    "### Confidence Intervals for Unknown Mean and Known Standard Deviation\n",
    "\n",
    "For a population with unknown mean $\\mu$ and known standard deviation $\\sigma$, a confidence interval for the population mean, based on a simple random sample (SRS) of size n, is $\\bar{x} \\pm z^{*}\\frac{\\sigma}{\\sqrt{n}}$, where $z^{*}$ is the upper (1-C)/2 critical value for the standard normal distribution.\n",
    "\n",
    "Note: This interval is only exact when the population distribution is normal. For large samples from other population distributions, the interval is approximately correct by the Central Limit Theorem.\n",
    "\n",
    "##### Example:<br>\n",
    "In the example above, the student calculated the sample mean of the boiling temperatures to be 101.82, with standard deviation 0.49. The critical value for a 95% confidence interval is 1.96, where (1-0.95)/2 = 0.025. A 95% confidence interval for the unknown mean $\\mu$ is ((101.82 - (1.96*0.49)), (101.82 + (1.96*0.49))) = (101.82 - 0.96, 101.82 + 0.96) = (100.86, 102.78).\n",
    "\n",
    "As the level of confidence decreases, the size of the corresponding interval will decrease. Suppose the student was interested in a 90% confidence interval for the boiling temperature. In this case, C = 0.90, and (1-C)/2 = 0.05. The critical value $z^{*}$ for this level is equal to 1.645, so the 90% confidence interval is ((101.82 - (1.645*0.49)), (101.82 + (1.645*0.49))) = (101.82 - 0.81, 101.82 + 0.81) = (101.01, 102.63)\n",
    "\n",
    "I am 95% confident that the true boiling temperature of this liquid is in the range of (101.01, 102.63). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f667769-03eb-4de9-9b49-de4ad8bdca5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence Interval: (22.30102483847719, 28.498975161522807)\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import norm\n",
    "def confidence_interval_known_std(data, alpha=0.05, std_dev=None):\n",
    "    \"\"\"\n",
    "    Construct a confidence interval for the population mean with a known standard deviation.\n",
    "\n",
    "    Parameters:\n",
    "    - data: NumPy array or list containing the sample data.\n",
    "    - alpha: Confidence level (default is 0.05 for a 95% confidence interval).\n",
    "    - std_dev: Known population standard deviation.\n",
    "\n",
    "    Returns:\n",
    "    - Confidence interval (lower bound, upper bound).\n",
    "    \"\"\"\n",
    "    sample_mean = np.mean(data)\n",
    "    z_critical = norm.ppf(1 - alpha / 2)  # Z-score for a two-tailed test\n",
    "\n",
    "    margin_of_error = z_critical * (std_dev / np.sqrt(len(data)))\n",
    "\n",
    "    lower_bound = sample_mean - margin_of_error\n",
    "    upper_bound = sample_mean + margin_of_error\n",
    "\n",
    "    return lower_bound, upper_bound\n",
    "\n",
    "# Example usage:\n",
    "sample_data = np.array([22, 25, 28, 18, 32, 27, 23, 20, 29, 30])\n",
    "known_std_dev = 5.0  # Replace with your known standard deviation\n",
    "\n",
    "confidence_interval = confidence_interval_known_std(sample_data, std_dev=known_std_dev)\n",
    "print(\"Confidence Interval:\", confidence_interval)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4211eb58-6560-4ed5-b6bc-ca55bd51f3b4",
   "metadata": {},
   "source": [
    "### Confidence Intervals for Unknown Mean and Unknown Standard Deviation\n",
    "\n",
    "In most practical research, the standard deviation for the population of interest is not known. In this case, the standard deviation $\\sigma$ is replaced by the estimated standard deviation s, also known as the standard error. Since the standard error is an estimate for the true value of the standard deviation, the distribution of the sample mean $\\bar{x}$ is no longer normal with mean $\\mu$ and standard deviation $\\frac{\\sigma}{\\sqrt{n}}$. Instead, the sample mean follows the t distribution with mean $\\mu$ and standard deviation $\\frac{s}{\\sqrt{n}}$. The t distribution is also described by its degrees of freedom. For a sample of size n, the t distribution will have n-1 degrees of freedom. The notation for a t distribution with k degrees of freedom is $t(k)$. As the sample size n increases, the t distribution becomes closer to the normal distribution, since the standard error approaches the true standard deviation $\\sigma$ for large n.\n",
    "\n",
    "For a population with unknown mean $\\mu$ and unknown standard deviation, a confidence interval for the population mean, based on a simple random sample (SRS) of size n, is $\\bar{x} \\pm t^{*}\\frac{s}{\\sqrt{n}}$, where $t^{*}$ is the upper (1-C)/2 critical value for the t distribution with n-1 degrees of freedom, t(n-1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b0926104-ada3-4183-9a21-abc4ed99fbd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence Interval: (22.127030421684026, 28.67296957831597)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(22.30102483847719, 28.498975161522807)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import t\n",
    "def confidence_interval_unknown_std(data, alpha=0.05):\n",
    "    \"\"\"\n",
    "    Construct a confidence interval for the population mean with an unknown standard deviation.\n",
    "\n",
    "    Parameters:\n",
    "    - data: NumPy array or list containing the sample data.\n",
    "    - alpha: Confidence level (default is 0.05 for a 95% confidence interval).\n",
    "\n",
    "    Returns:\n",
    "    - Confidence interval (lower bound, upper bound).\n",
    "    \"\"\"\n",
    "    sample_mean = np.mean(data)\n",
    "    sample_std = np.std(data, ddof=1)  # Use sample standard deviation (ddof=1 for unbiased estimate)\n",
    "    n = len(data)\n",
    "\n",
    "    t_critical = t.ppf(1 - alpha / 2, df = n - 1)  # T-score for a two-tailed test\n",
    "\n",
    "    margin_of_error = t_critical * (sample_std / np.sqrt(n))\n",
    "\n",
    "    lower_bound = sample_mean - margin_of_error\n",
    "    upper_bound = sample_mean + margin_of_error\n",
    "\n",
    "    return lower_bound, upper_bound\n",
    "\n",
    "# Example usage:\n",
    "sample_data = np.array([22, 25, 28, 18, 32, 27, 23, 20, 29, 30])\n",
    "\n",
    "confidence_interval = confidence_interval_unknown_std(sample_data)\n",
    "print(\"Confidence Interval:\", confidence_interval)\n",
    "\n",
    "(22.30102483847719, 28.498975161522807)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195eadce-9faa-4b8f-bfd6-8c05a91ec718",
   "metadata": {},
   "source": [
    "Because of the distribution assumption, z vs t. The t distribution is going to make a wider \"guess\" comparing to a normal distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a4fd45-80be-499c-a81d-130d061e5bb1",
   "metadata": {},
   "source": [
    "### 2. Tests of Significance\n",
    "\n",
    "Once sample data has been gathered through an observational study or experiment, statistical inference allows analysts to assess evidence in favor or some claim about the population from which the sample has been drawn. The methods of inference used to support or reject claims based on sample data are known as tests of significance.\n",
    "\n",
    "Every test of significance begins with a null hypothesis $H_{0}$. $H_{0}$ represents a theory that has been put forward, either because it is believed to be true or because it is to be used as a basis for argument, but has not been proved. For example, in a clinical trial of a new drug, the null hypothesis might be that the new drug is no better, on average, than the current drug. We would write $H_{0}$: there is no difference between the two drugs on average.\n",
    "\n",
    "The alternative hypothesis, $H_{a}$, is a statement of what a statistical hypothesis test is set up to establish. For example, in a clinical trial of a new drug, the alternative hypothesis might be that the new drug has a different effect, on average, compared to that of the current drug. We would write $H_{a}$: the two drugs have different effects, on average. The alternative hypothesis might also be that the new drug is better, on average, than the current drug. In this case we would write $H_{a}$: the new drug is better than the current drug, on average.\n",
    "\n",
    "The final conclusion once the test has been carried out is always given in terms of the null hypothesis. We either \"reject $H_{0}$ in favor of $H_{a}$\" or \"do not reject $H_{0}$\"; we never conclude \"reject $H_{a}$\", or even \"accept $H_{a}$\".\n",
    "\n",
    "If we conclude \"do not reject $H_{0}$\", this does not necessarily mean that the null hypothesis is true, it only suggests that there is not sufficient evidence against $H_{0}$ in favor of $H_{a}$; rejecting the null hypothesis then, suggests that the alternative hypothesis may be true.\n",
    "\n",
    "(Definitions taken from Valerie J. Easton and John H. McColl's Statistics Glossary v1.1)\n",
    "\n",
    "Hypotheses are always stated in terms of population parameter, such as the mean $\\mu$. An alternative hypothesis may be one-sided or two-sided. A one-sided hypothesis claims that a parameter is either larger or smaller than the value given by the null hypothesis. A two-sided hypothesis claims that a parameter is simply not equal to the value given by the null hypothesis -- the direction does not matter.\n",
    "\n",
    "Hypotheses for a one-sided test for a population mean take the following form:\n",
    "$H_{0} = k$,\n",
    "$H_{a} > k$\n",
    "or\n",
    "$H_{0} = k$,\n",
    "$H_{a} < k$\n",
    "\n",
    "Hypotheses for a two-sided test for a population mean take the following form:\n",
    "$H_{0} = k$,\n",
    "$H_{a} \\neq k$\n",
    "\n",
    "A confidence interval gives an estimated range of values which is likely to include an unknown population parameter, the estimated range being calculated from a given set of sample data. (Definition taken from Valerie J. Easton and John H. McColl's Statistics Glossary v1.1)\n",
    "\n",
    "##### Example\n",
    "Suppose a test has been given to all high school students in a certain state. The mean test score for the entire state is 70, with standard deviation equal to 10. Members of the school board suspect that female students have a higher mean score on the test than male students, because the mean score $\\bar{x}$ from a random sample of 64 female students is equal to 73. Does this provide strong evidence that the overall mean for female students is higher?\n",
    "\n",
    "The null hypothesis $H_{0}$ claims that there is no difference between the mean score for female students and the mean for the entire population, so that $H_{0}$ = 70. The alternative hypothesis claims that the mean for female students is higher than the entire student population mean, so that $H_{a}$ > 70."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c6f878e-ae6c-484e-9651-a337fcdbe03a",
   "metadata": {},
   "source": [
    "### Significance Tests for Population Mean with known Population Standard Deviation\n",
    "\n",
    "Once null and alternative hypotheses have been formulated for a particular claim, the next step is to compute a test statistic. For claims about a population mean from a population with a normal distribution or for any sample with large sample size n (for which the sample mean will follow a normal distribution by the Central Limit Theorem), if the standard deviation $\\sigma$ is known, the appropriate significance test is known as the z-test, where the test statistic is defined as:\n",
    "$$z = \\frac{\\bar{x} - \\mu_{0}}{\\frac{\\sigma}{\\sqrt{n}}}$$\n",
    "\n",
    "The test statistic follows the standard normal distribution (with mean = 0 and standard deviation = 1). The test statistic z is used to compute the $P-value$ for the standard normal distribution, the probability that a value at least as extreme as the test statistic would be observed under the null hypothesis. Given the null hypothesis that the population mean  is equal to a given value 0, the P-values for testing H0 against each of the possible alternative hypotheses are:\n",
    "\n",
    "$P(Z > z)$ for $H_{a}: > 0 $ <br>\n",
    "$P(Z < z)$ for $H_{a}: < 0 $ <br>\n",
    "$2P(Z>|z|)$ for $H_{a}: 0 $. <br>\n",
    "\n",
    "The probability is doubled for the two-sided test, since the two-sided alternative hypothesis considers the possibility of observing extreme values on either tail of the normal distribution.\n",
    "\n",
    "##### Example:\n",
    "\n",
    "In the test score example above, where the sample mean equals 73 and the population standard deviation is equal to 10, the test statistic is computed as follows:\n",
    "$z = (73 - 70)/(\\frac{10}{\\sqrt{64}}) = 3/1.25 = 2.4$. Since this is a one-sided test, the P-value is equal to the probability that of observing a value greater than 2.4 in the standard normal distribution, or P(Z > 2.4) = 1 - P(Z < 2.4) = 1 - 0.9918 = 0.0082. The P-value is less than 0.01, indicating that it is highly unlikely that these results would be observed under the null hypothesis. The school board can confidently reject $H_{0} given this result, although they cannot conclude any additional information about the mean of the distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a91e85af-f942-49b5-9961-def0b6e020b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z-Statistic: 0.9012336827794607\n",
      "Critical Z-Value: 1.959963984540054\n",
      "P-Value: 0.3674640856208802\n",
      "Fail to reject the null hypothesis. There is not enough evidence to suggest a difference.\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "# H0 is my sample mean equals to the pop mean\n",
    "# Ha is sample mean doesn't equal to the pop mean\n",
    "\n",
    "# Generate a sample dataset (replace this with your actual data)\n",
    "np.random.seed(100)\n",
    "sample_data = np.random.normal(loc = 15, scale = 5, size = 30)  # Mean = 15, Standard Deviation = 5, Sample Size = 30\n",
    "\n",
    "# Population parameters (replace this with your known or hypothesized population mean)\n",
    "pop_mean = 15  # the population mean you want to test\n",
    "pop_std_dev = 5  # Known population standard deviation\n",
    "\n",
    "# Calculate the z-statistic\n",
    "z_statistic = (np.mean(sample_data) - pop_mean) / (pop_std_dev / np.sqrt(len(sample_data)))\n",
    "\n",
    "# Set the significance level(0.95) = 1 - confident level(0.95) (alpha)\n",
    "alpha = 0.05\n",
    "\n",
    "# Calculate the critical z-value for a two-tailed test\n",
    "critical_z_value = norm.ppf(1 - alpha / 2)\n",
    "\n",
    "# Perform the hypothesis test\n",
    "p_value = 2 * (1 - norm.cdf(np.abs(z_statistic)))\n",
    "\n",
    "# Print the results\n",
    "print(\"Z-Statistic:\", z_statistic)\n",
    "print(\"Critical Z-Value:\", critical_z_value)\n",
    "print(\"P-Value:\", p_value)\n",
    "\n",
    "# Compare the p-value with the significance level\n",
    "if p_value < alpha:\n",
    "    print(\"Reject the null hypothesis. There is significant evidence to suggest a difference.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis. There is not enough evidence to suggest a difference.\")\n",
    "    \n",
    "# H0: my true population mean equals to 15, H0: true pupulation mean = 20\n",
    "# Ha: my true population mean is not equal to 15, Ha: true pupulation mean != 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba86926-8bbe-431a-bdbe-af723ec1c921",
   "metadata": {},
   "source": [
    "### Significance Tests for Population Mean with Unknown Population Standard Deviation\n",
    "\n",
    "In most practical research, the standard deviation for the population of interest is not known. In this case, the standard deviation $\\sigma$ is replaced by the estimated standard deviation s, also known as the standard error. Since the standard error is an estimate for the true value of the standard deviation, the distribution of the sample mean $\\bar{x}$ is no longer normal with mean $\\mu$ and standard deviation $\\frac{\\sigma}{\\sqrt{n}}$. Instead, the sample mean follows the t distribution with mean ${\\mu}$ and standard deviation $\\frac{s}{\\sqrt{n}}$. The t distribution is also described by its degrees of freedom. For a sample of size n, the t distribution will have n-1 degrees of freedom. The notation for a t distribution with k degrees of freedom is t(k). As the sample size n increases, the t distribution becomes closer to the normal distribution, since the standard error approaches the true standard deviation $\\sigma$ for large n.\n",
    "\n",
    "For claims about a population mean from a population with a normal distribution or for any sample with large sample size n (for which the sample mean will follow a normal distribution by the Central Limit Theorem) with unknown standard deviation, the appropriate significance test is known as the t-test, where the test statistic is defined as:\n",
    "$$t = \\frac{\\bar{x} - \\mu_{0}}{\\frac{s}{\\sqrt{n}}}$$\n",
    "\n",
    "The test statistic follows the t distribution with n-1 degrees of freedom. The test statistic z is used to compute the P-value for the t distribution, the probability that a value at least as extreme as the test statistic would be observed under the null hypothesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5052fb9c-1f57-4904-868f-cca5e60b0e7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T-Statistic: 0.07213517949624637\n",
      "P-Value: 0.9429895415189937\n",
      "Fail to reject the null hypothesis. There is not enough evidence to suggest a difference.\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import ttest_1samp\n",
    "\n",
    "# Generate a sample dataset (replace this with your actual data)\n",
    "np.random.seed(42)\n",
    "sample_data = np.random.normal(loc=15, scale=5, size=30)  # Mean = 15, Standard Deviation = 5, Sample Size = 30\n",
    "\n",
    "# Population parameter (replace this with your known or hypothesized population mean)\n",
    "pop_mean = 14  # the population mean you want to test\n",
    "\n",
    "# Perform the one-sample t-test\n",
    "t_statistic, p_value = ttest_1samp(sample_data, pop_mean)\n",
    "\n",
    "# Set the significance level (alpha)\n",
    "alpha = 0.05\n",
    "\n",
    "# Print the results\n",
    "print(\"T-Statistic:\", t_statistic)\n",
    "print(\"P-Value:\", p_value)\n",
    "\n",
    "# Compare the p-value with the significance level\n",
    "if p_value < alpha:\n",
    "    print(\"Reject the null hypothesis. There is significant evidence to suggest a difference.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis. There is not enough evidence to suggest a difference.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014e128f-0328-4e57-97f4-46b814f33ed7",
   "metadata": {},
   "source": [
    "### The Sign Test\n",
    "Another method of analysis for matched pairs data is a distribution-free test known as the sign test. This test does not require any normality assumptions about the data, and simply involves counting the number of positive differences between the matched pairs and relating these to a binomial distribution. The concept behind the sign test reasons that if there is no true difference, then the probability of observing an increase in each pair is equal to the probability of observing a decrease in each pair: p = 1/2. Assuming each pair is independent, the null hypothesis follows the distribution B(n,1/2), where n is the number of pairs where some difference is observed.\n",
    "\n",
    "To perform a sign test on matched pairs data, take the difference between the two measurements in each pair and count the number of non-zero differences n. Of these, count the number of positive differences X. Determine the probability of observing X positive differences for a $B(n,1/2)$ distribution, and use this probability as a P-value for the null hypothesis.\n",
    "\n",
    "##### Example<br>\n",
    "In the \"Helium Football\" example above, 2 of the 39 trials recorded no difference between kicks for the air-filled and helium-filled balls. Of the remaining 37 trials, 20 recorded a positive difference between the two kicks. Under the null hypothesis, p = 1/2, the differences would follow the B(37,1/2) distribution. The probability of observing 20 or more positive differences, P(X>20) = 1 - P(X<19) = 1 - 0.6286 = 0.3714. This value indicates that there is not strong evidence against the null hypothesis, as observed previously with the t-test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "837cd96a-c5f2-4417-83e2-e841094dbcf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive signs: 13\n",
      "Number of negative signs: 17\n",
      "P-Value: 0.5846647117286922\n",
      "Fail to reject the null hypothesis. There is not enough evidence to suggest a difference in medians.\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import binom_test\n",
    "\n",
    "# Generate a sample dataset (replace this with your actual data)\n",
    "np.random.seed(42)\n",
    "sample_data = np.random.normal(loc=15, scale=5, size=30)  # Sample data\n",
    "\n",
    "# Hypothesized median (replace this with your hypothesized value)\n",
    "hypothesized_median = 14\n",
    "\n",
    "# Perform the one-sample sign test\n",
    "signs = np.sign(sample_data - hypothesized_median)\n",
    "num_positive = np.sum(signs > 0)\n",
    "num_negative = np.sum(signs < 0)\n",
    "\n",
    "# Use a binomial test to check if the number of positive signs is significantly different from the number of negative signs\n",
    "p_value = binom_test(min(num_positive, num_negative), n=num_positive + num_negative)\n",
    "\n",
    "# Set the significance level (alpha)\n",
    "alpha = 0.05\n",
    "\n",
    "# Print the results\n",
    "print(\"Number of positive signs:\", num_positive)\n",
    "print(\"Number of negative signs:\", num_negative)\n",
    "print(\"P-Value:\", p_value)\n",
    "\n",
    "# Compare the p-value with the significance level\n",
    "if p_value < alpha:\n",
    "    print(\"Reject the null hypothesis. There is significant evidence to suggest a difference in medians.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis. There is not enough evidence to suggest a difference in medians.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0adb1b-df75-43f6-83af-e781b65ece1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
