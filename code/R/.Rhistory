setwd("C:/Users/YJY/eclipse-workspace/Data-Analytics-and-Modeling/code/R")
#
# Exploratory Data Analysis
# Jeff Smith with
#    material from http://r4ds.had.co.nz/exploratory-data-analysis.html
#
library("tidyverse")
# Read in and add some new variables
(aure <- read_csv("data\\au_real_estate_2017_anon.csv"))
# Read in and add some new variables
(aure <- read_csv("..\\..\\data\\au_real_estate_2017_anon.csv"))
View(aure)
# Add some columns
aure <- aure %>%
mutate(
Baths = BathsFull + BathsHalf,
PType = substring(MLSID, 1, 1),
NBed  = as.character(Bedrooms),
NBath = as.character(Baths)
)
View(aure)
# or a color tile version - Note the use of the pipe with
# ggplot.  It's limited in that you still need to use the
# '+ notation' to add components.
aure
%>%
# or a color tile version - Note the use of the pipe with
# ggplot.  It's limited in that you still need to use the
# '+ notation' to add components.
aure %>%
count(NBed, NBath) %>%
ggplot(mapping = aes(x = NBed, y = NBath)) +
geom_tile(mapping = aes(fill = n))
# or a color tile version - Note the use of the pipe with
# ggplot.  It's limited in that you still need to use the
# '+ notation' to add components.
aure
# or a color tile version - Note the use of the pipe with
# ggplot.  It's limited in that you still need to use the
# '+ notation' to add components.
aure %>%
count(NBed, NBath) %>%
ggplot(mapping = aes(x = NBed, y = NBath)) +
geom_tile(mapping = aes(fill = n))
# baths vs bedrooms
ggplot(data = aure) +
geom_count(mapping = aes(x = NBed, y = NBath))
# or a color tile version - Note the use of the pipe with
# ggplot.  It's limited in that you still need to use the
# '+ notation' to add components.
aure %>%
count(NBed, NBath) %>%
ggplot(mapping = aes(x = NBed, y = NBath)) +
geom_tile(mapping = aes(fill = n))
#
# Aggregation/Grouping ------------------------------------------------
#
# summarize the data
summarise(aure, num=n(),
tot_dollars=sum(Price),
avg_dollars=mean(Price),
dom=mean(DaysOnMarket),
dom1=median(DaysOnMarket))
# By Subdivision- group, summarize, order by number of units
(subdivision <- aure %>%
group_by(Subdivision) %>%
summarize(
num = n(),
avg_price = mean(Price),
med_price = median(Price),
avg_sqft = mean(SqFt),
med_sqft = median(SqFt),
avg_dom = mean(DaysOnMarket),
med_dom = median(DaysOnMarket)
) %>%
arrange(desc(num)))
# By median price
aure %>%
group_by(Subdivision) %>%
summarize(
num = n(),
avg_price = mean(Price),
med_price = median(Price),
avg_sqft = mean(SqFt),
med_sqft = median(SqFt),
avg_dom = mean(DaysOnMarket),
med_dom = median(DaysOnMarket)
) %>%
arrange(desc(med_price))
# Outliers -- subdivisions with a single unit - remove them
aure %>%
group_by(Subdivision) %>%
summarize(
num = n(),
avg_price = mean(Price),
med_price = median(Price),
avg_sqft = mean(SqFt),
med_sqft = median(SqFt),
avg_dom = mean(DaysOnMarket),
med_dom = median(DaysOnMarket)
) %>%
filter(num > 5) %>%
arrange(desc(med_price))
# which subdivsions sell?
ggplot(data = subdivision) +
geom_col(mapping = aes(x=Subdivision, y=num))
# filter down
ggplot(data = filter(subdivision, num > 20)) +
geom_col(mapping = aes(x=Subdivision, y=num))
# flip to see the subdivisions
ggplot(data = filter(subdivision, num > 20)) +
geom_col(mapping = aes(x=Subdivision, y=num)) +
coord_flip()
# Median price by subdivision?
ggplot(data = filter(subdivision, num > 20)) +
geom_col(mapping = aes(x=Subdivision, y=med_price)) +
coord_flip()
(agent_prodn <- summarize(by_agent,
num=n(),
dollars = sum(Price),
dom=mean(DaysOnMarket),
dom1=median(DaysOnMarket)) %>%
arrange(desc(num)))
# Transactions by firm
# Agency Production - Note that I created the
# new tibble here rather than using the pipe as above.
by_agency <- group_by(aure, Firm)
library("modelr")
# Dataset ------
# Read our simple data set
(df <- read_csv("..\\..\\data\\reg_sample.csv"))
# Let's have a look (generally the first step with new data)
ggplot(data=df) +
geom_point(aes(x=x, y=y),size=3)
# First model ------------------
# Seems like there might be a linear relationship between the
# x and y variables.
# Define a model family using y = w1 + w2*x (intercept/slope line formula)
#
# Model instance - select values for w1, w2
w1 <- 0
w2 <- 150
ggplot(df, aes(x, y)) +
geom_abline(aes(intercept = w1, slope = w2)) +
geom_point(size=3)
# Random models --------------------
# Generate some random models
num <- 200
models <- tibble(
w1 = runif(num, -500000, 500000),
w2 = runif(num, -100, 250)
)
# plot the random models with the data
ggplot(df, aes(x, y)) +
geom_abline(aes(intercept = w1, slope = w2), data = models, alpha = 1/4) +
geom_point(size=3)
# Model function --------------------
# Create a model function - takes the model parameters
# (w1 and w2) and the x values and returns the y values
model1 <- function(w, data) {
w[1] + data$x * w[2]
}
# sample invocation using the previously
# defined (single values) w1 and w2
model1(c(w1, w2), df)
# Distance metric ------
# Create a distance measure for a model.  Two
# common distance metrics -- RMS (root-mean-squared)
# and RSS (residual sum-of-squares) -- comment
# one of the two methods out.
measure_distance <- function(w, data) {
diff <- data$y - model1(w, data)
# RMS
sqrt(mean(diff ^ 2))
# RSS
#  sum(diff^2)
}
# sample invocation
measure_distance(c(w1, w2), df)
View(models)
# sample invocation
measure_distance(c(w1, w2), df)
# Purrr -----
# I need a 2-parameter function for purrr -- code the function
# so that the sample dataset is used automatically (i.e.,
# the df is not a parameter of this function, but is used internally)
sim1_dist <- function(w1, w2) {
measure_distance(c(w1, w2), df)
}
# sample invocation - same as the measure_distance above.
sim1_dist(w1, w2)
# Use purrr to run the model function for each model (row)
# and store the distance in the tibble (using mutate)
models <- models %>%
mutate(dist = purrr::map2_dbl(w1, w2, sim1_dist))
# See the models tibble -----> a new column withe the
# "goodness measure".
?map2_dbl
# Plot the "top 10" best models.  How do we pick the
# 10 best of our models?
ggplot(df, aes(x, y)) +
geom_point(size = 2, colour = "grey30") +
geom_abline(
aes(intercept = w1, slope = w2, colour = -dist),
data = filter(models, rank(dist) <= 10)
)
# to see the top 10
filter(models, rank(dist) <= 10)
# Try looking at the models in model parameter space (w1~w2).
ggplot(models, aes(w1, w2)) +
geom_point(data = filter(models, rank(dist) <= 10), size = 4, colour = "red") +
geom_point(aes(colour = -dist))
grid <- expand.grid(
w1 = seq(-250000, 200000, length=25),
w2 = seq(40, 250, length=25)
) %>%
mutate(dist = purrr::map2_dbl(w1, w2, sim1_dist))
# view the models with the best ones identified in parameter space
grid %>%
ggplot(aes(w1, w2)) +
geom_point(data = filter(grid, rank(dist) <= 10), size = 4, colour = "red") +
geom_point(aes(colour = -dist))
# plot the best 10 with the data points
ggplot(df, aes(x, y)) +
geom_point(size = 2, colour = "grey30") +
geom_abline(
aes(intercept = w1, slope = w2, colour = -dist),
data = filter(grid, rank(dist) <= 10)
)
# Let's do one more grid refinement
# Go back and look a the parameter space view
grid <- expand.grid(
w1 = seq(-100000, 50000, length=25),
w2 = seq(100, 180, length=25)
) %>%
mutate(dist = purrr::map2_dbl(w1, w2, sim1_dist))
#
# Best Fit Models -----
#
# Optim uses the Newton-Raphson method
best <- optim(c(-500000, 0), measure_distance, data = df)
best$par
?optim
# remember the function call - Optim replicates this in its search
# process
measure_distance(c(0, 150), df)
# Plot the best
ggplot(df, aes(x, y)) +
geom_point(size = 2, colour = "grey30") +
geom_abline(intercept = best$par[1], slope = best$par[2])
